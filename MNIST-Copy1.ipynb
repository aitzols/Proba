{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font size=\"+4\"><center>\n",
    "    Casos prácticos de modelado <br/>\n",
    "    mediante redes neuronales <br/>\n",
    "    usando TensorFlow<center/></font><h1/>\n",
    "    \n",
    "<img src=\"img/Ecosystem.png\" alt=\"Ecosystem\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase the cell width of the Jupyter notebook in the browser\n",
    "# https://stackoverflow.com/questions/21971449/how-do-i-increase-the-cell-width-of-the-jupyter-ipython-notebook-in-my-browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='http://yann.lecun.com/exdb/mnist', width=100%, height=400></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src='http://yann.lecun.com/exdb/mnist', width=100%, height=400></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST DataBase](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png \"MNIST DataBase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2.0\n",
    "\n",
    "El código que se muestra a continuación está basado en TensorFlow 2.0. Mucho del contenido de este cuaderno está también disponible en la [Guia inicial de TensorFlow 2.0 para principiantes](https://www.tensorflow.org/tutorials/quickstart/beginner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y análisis de la base de datos\n",
    "\n",
    "TensorFlow incorpora un sencillo mecanismo para descargar la Base de Datos MNIST:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos está compuesta por 60.000 muestras de entrenamiento (`x_train`), 10.000 de test (`x_test`) y sus correspondientes etiquetas (`y_train` e `y_test`). Cada muestra representa una imagen de 28x28 píxeles. Las muestras y las etiquetas descargadas están guardadas en arrays n-dimensionales de `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28)\n",
      "<class 'numpy.ndarray'> (60000,)\n",
      "<class 'numpy.ndarray'> (10000, 28, 28)\n",
      "<class 'numpy.ndarray'> (10000,)\n"
     ]
    }
   ],
   "source": [
    "for x in (x_train, y_train, x_test, y_test) :\n",
    "    print(type(x),x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante el módulo `matplotlib` podemos visualizar el contenido de las primeras 10 muestras de entrenamiento, así como sus respectivas etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADSCAYAAAB0FBqGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3xUVfrH8c9JgdAhlAhKhwiCigpiQyxYfwoqKKL8VNYGiIUFdXXdpujq6uqqC9gQLLvqqqisdRdFfq4iigq6SFWqFAHpEEg5vz+emYSJARJI5swk3/frlVcmd+5MntzMnHnuuc85x3nvERGR+EsJHYCISFWlBlhEJBA1wCIigagBFhEJRA2wiEggaoBFRAJRAywiEkjCNsDOuQ+dcznOuS2Rr3mhYwrNOZfpnHvNObfVObfEOXdJ6JgShXOufeT18nzoWEJzzg1zzs1wzu1wzk0IHU+icM51dM594Jzb6Jxb6Jw7P3RMCdsARwzz3teOfB0cOpgEMBrYCWQBlwJjnXOdwoaUMEYDn4cOIkGsAEYBT4cOJFE459KAN4A3gUzgGuB551x2yLgSvQGWCOdcLaAv8Bvv/Rbv/X+AScD/ho0sPOfcxcAG4P3QsSQC7/1E7/3rwLrQsSSQDkAz4CHvfb73/gPgYwK/fxK9Af6jc26tc+5j59xJoYMJLBvI897P32XbLKBKZ8DOubrAncAvQ8ciSccBnUMGkMgN8K1AG+BA4Angn865tmFDCqo2sKnYto1AnQCxJJK7gHHe++WhA5GENg/4EbjZOZfunDsd6AnUDBlUwjbA3vvp3vvN3vsd3vtnsNOFs0PHFdAWoG6xbXWBzQFiSQjOuS5AL+Ch0LFIYvPe5wLnAf8DrAJGAP8Agn5wp4X85WXksVOGqmo+kOaca++9XxDZdjgwO2BMoZ0EtAKWOufAzhJSnXOHeO+PDBiXJCDv/ddY1guAc+4T4JlwESVoBuycq++cO8M5l+GcS3POXQqcCLwbOrZQvPdbgYnAnc65Ws6544E+wHNhIwvqCaAt0CXy9RjwFnBGyKBCi7xnMoBU7AMpI1IFUKU55w6LHIuazrmRQFNgQsiYErIBBtKxMpo1wFrgeuC8YhegqqKhQA2sL+sFYIj3vspmwN77bd77VdEvrJsmx3u/JnRsgd0BbAd+BQyM3L4jaESJ4X+Bldj751TgNO/9jpABOU3ILiISRqJmwCIilZ4aYBGRQNQAi4gEogZYRCQQNcAiIoGUqTawmqvuM6hVUbEkhBy2stPvKPWAj6pwTAA2s36t975xafbVMSlZVTguev+UbHevlTI1wBnUors7tfyiSkDTfdkm1KoKxwRgsn9lSWn31TEpWVU4Lnr/lGx3rxV1QYiIBKIGWEQkEDXAIiKBqAEWEQlEDbCISCBqgEVEAqnyc4Qms7xTjgJg5VCbUW/WsTa39OHTLgeg2ehqAKRO+TJAdCKyN8qARUQCSbgM2KVZSKmNG5V4/7yRrQDIr1kAQMu2PwJQc6gNvln1oGV9X3Z9qfAxa/O3AtD95REAtPvlp+UcdXwV9DwCgEee/isA7dLtmBVE7v/q2PEAzOuaD8DNrY6Jb4BJYGu/7gDc96exhdvuuugyAPyM/waJKYTv7j8WgDmX2Gsp3aUCcOLQawr3qfH6Z/EPrIpQBiwiEkjcM+DUju0B8NXTAVjRsz4A24+xLDWznn3/6PCXSnj0z72zzVZlv++vZwIw/dC/A7Aod3vhPveuPg2AZh8l9+ofuad3BeCWMbYMXHa6ZfsFkdz3+9xcADYWVAfgCPvGjrO6AVBjyjeFz1WQk1PxAe/G9j5H2/eGlm1lPj0t7jH82NVyj7sWnxv3350IVg0/DoAP+/8JgFxfLXaH5H6rJA1lwCIigcQlA84/qWiF8AcnjAaKsrd9leutf/O3j14BQNpW+8g+9uVhANT5Ia9w3+prLRuuOWP6fv3OeEutWxeArSd2AGD4Q5bdn1xjS2SP2M/PCestq3l/jPXrffz7RwD491OPAXDI88MK921za/yzzqgVJ1rcNdtusA1Px/GXp1jW7VvYa+LUJnML73rfHRfHQMLa0tzOmjJT9u99mAx2nmFnjksutb95yJFTAbipQewav4c+dT0ANVdaW7LhOKsuavk3e71We29GucemDFhEJBA1wCIigcSlC6L6vBWFt7/IaQ5AdvrqUj12xEorofp+i5WlTWj7CgAbC+w0IeuRT/b6HMl6PWH5swcC8Hm30aXa/84mnwPwbm07lR60+HQAnmk1GYC6h6wr7xD3yR/OeRmA++acHvffndq2JQBze1q/R5fPBhbe1+zzb0p8TGWy5UIrv3v1/IcjW6x887EN1s01+SI7Xa+1ZHbhYwpITmsGW1fco7fY+6drdeu2TInknZcv7gXAEfWWAjDrqodjHh/d77jMAQBkvlf+MSoDFhEJJC4ZcN7KVYW3H73vQgDuPtPKzVK/rg3ArKGPxjxm1NrDAFjYqyYA+RtWAnDJsUMBWHyD7deaWRUUdTjRIcYvdLHi+BRiL5QMWmIrCMyY3BGAb660/aZszwCgyQy7wLRwvWU16fdMsecp9UIxFSvd5e19pwqS9tS2mJ+3f1c3UCTxlXOOlf797o+W+Wenx74YnnnSyjgP+HbvZ5SJykUu7Of0OhyAV2+7H4BmaVaPeeUSK0dd8sDBANR6ayYAU2q2AGDqa9n2uPaTYp5308yGAGRWQMzKgEVEAon7QIzM8Vb+1Pif9qmSv+4nADp1/gUAs0+0T+hJT/QEoMmG2E9kN80y3tbhqqgqzO6HGFsvXO+55wOQ2s/OHur/j/VuH/KclZdlj14GQMqyrwBo8JE9b+7d1vf16mFF9V6/ONlOIeI5UU/BCV0A6JHxn7j9zuJa1YrtB28+OT9QJPG1cqANvDm5RnQAjpXjRftBD3g4eTPfqJXDrP/6s5HRvlzLfC9caINt8vraQKWaa60cNXptaMU1dsY5vX1sH3B0kFe7x+19VRHnbcqARUQCCTYZT/7a2Ewkd1NsP2enS78FYM1Y+6SmoPJmKu6oTgCs/aX13UYHqXxhdeB8sOUQANa9aBUkDddb+l/veZtUqF7kefb2CZ2VWr3w9rqbrC+0yZT9Cr1MlpxTw35nas34/dKItFbWz9cvM7Z/r8ai9YW3K+MrLO0gq6SZ3cMmaIoOYJpjySBLH7R+z1ok1yClXS141Co75l1g15GiVRsd/z0YgA4jFwM/b3OiBg95o8Tto+62aV0bLKu4021lwCIigSTMdJQdb7VhgYMOtSv841u+D0DPC68DoM5LyT2FZHEpNYuywLw/bQLg0w4TAViUtxOAX95u02c2+MjqFJvUsqk3yyNTO7rpEgAWl8NzlVZau80xP+fMrR+3373sL7UAOL665UfjNh1kd2zYFLcY4im1k13p7/r3kqfW7D/RrgG0fTU531ff/bloitV5F1id78YC69++cO4lABx8vbUp+ZtjX3cptey1sK6fVVr1qW3VEinYGVqHl63NaTeh4i80KQMWEQkkYTLg/A0bAVg3xGpbl06y/tBfjXoWgNsusgoA/5X1eDa/O/Lp5JNznNv2np0Kb7/XYUzMfVfdOByAOq9bdhKuarZiNZlR/mOsUhtZdc3qvta3mXnRcgCmZo+L7GG10mNHn2cxrE7+q/8lWdLbjsMrDb+KbLFrKZd8ZxUB2fd+ByRfv3dqVhMAnjm/6D0TrRKKZr7VTlsS2R4rpYtdS+n89BwARmU9ErnHro0cP/NiAA7+vd0fj2OjDFhEJJCEyYCjCmbZp8/Ff7gZgL/97gEAZh5jmTCRrp9Otaz2tf2TNkIu7/vF8QuyHBx218zC29Ex59ERbuW9BEx0mZncXU4WUl34M4ftmfZ319rDPgU9rDbap9rIrWW9LFvZ2cwu46dUszzlXz3sCnh0gNeqfNvvN9/bmdNPBZYP1Uyx/bOmW79g+KNQvn4aZPMfvDb4/sgWW/hg8DKrq8+93I5L/pqlcY+tPLgMiz86r8Ouatxg1UOupVULLRhs/fyn97Ja9+FNngCgRZr19UYz5PzIWbR7yeabyd+woAIiL5kyYBGRQBIuA46KLlMzbJ5dkax7r/XlvdDGpiSafZmNFuvQ/CoADv6DfZbkL/g+rnGW1Yb/tQzljqwHCrcVROZ6+OJf1kfVgvLtl4zWfhbs0iv27hz7Xe2J30i4HTnpkTgs4xh/+0MATBrWZbePubXhUwCkRGbt2u6tQmRFvv1Nf11zEgC9Jt8EQP2v7Fg2/ZfNtueW2OtmzRzLerJSLXP2lWzms2jVwyej/hrZkhFz/7TlrQBovji5Fxz1OVYcP31HeuG27tXtf/rG5BeB2Nf5riZvtwx3QeRUMLqwwYyd9pqp/2z8h9cqAxYRCSRhM+Ao97H1lW7rZ1c/u/W3ZUOm32rjtueebBnSpa1sbtmNJ8Q7wrLJs0SMerssBTMtx/q12jxr8ybvb9VDtMZ47gOdI1u+AODS788q3KfDjYuA+F4FbzfQrsh3+qP13zfv9sNeHzPlR6tmWPOO9ec1nG3ZTrV3P4/sYT9nE7tcTPTv+uFWmxu5W3XLbl7ccuC+BZ/g5t9u//Po2U5xLe6178ne552/2mrhfzfkqsJtDzxmFRGHRd5Sz2+yPuBRU3sDkD3B6oPTVlulVZMXbP6Zk5t/AMDlU+y5ir+G4kEZsIhIIAmfAUdFP/myHrHvObdYnljT2cfek63eBOCc860vsOZryTO2fV2+zYm8v5Uc0cx33r2HAjC3j/UHvrPNaqdXjG5XuG+d9eFGQLW+rex9bU3Zt6v2NU9cE/PzHVP6ApBN+VaahBKdQW9U19dLvP+0/1pta+0Zyd33W9yuC2Te3vroEvcp/j/e3Mf2e6uFzf2Q6y3/rLE43MKkyoBFRAJJ+Aw4OofsdxfaVd3OXRYDRZlv1KM/WSZQ84349+Psr5Ef2yoh2ZG+2rKKZkE/RmZTm9PVMt9Tv+kPQK0zrTKkDsk57r88tXwj2XtBY909wWpbO6fH/l0jV54IQL0BNttbso14qwh5NSzfLF4V1HqCnV2FGHGqDFhEJJCEy4BdV7tyPz8yquXJ458B4MSMnSXuv8PbVfBPf2ptGwpWVnCE+ykyUitll8++h094AYDRZJfpqZbcaTXFr172IFA0j/CRn9k8ps3O/3a/QpXEd0S12Kwuatr4IwFosr5yznWxL+q8GDkD/HPYOHalDFhEJJDgGXBa65YAfDeoGQC/72+jWfrWXrvHx92+2tZ/mvqwTQ7R4JkkWSQu0lW362idnjVspv6bJtjaVG3H233pq2y+gtU9GwOQ2d9GdV3fwuZKPqum9RlP2poFwGXf2Mq2jR7f0+wKVVOqs1xjfbaNoDrgnZDR7L9lr9iZYrqbWeL9TT+094/6fotsvjg6h/C+XWupCMqARUQCiXsGHF2ba+NRTQHof+e7AAyuP3GPjxux0j69po2xzDdzgtX4NShIksx3DzKc/RvmnPYYAP/pYRUfC3YcAMCgeotLfNyNK3oA8O4nVinS/kZVOexOvo+ccSR5yhGtePlLl+eBor7f6GoQ3d6xOvgOS9T/X9zGNon3z0+8iEREqgg1wCIigVRoF0RaUzuF/unpootCQ1pPBWBAndV7fOywH2xWnS/H2ul1o1dsKGXm5uTucsj60IZS33rtsYXb7jsg9m+KltydkLE4ZvtXO+zzcsDUawDIHmQXE9prgEWpbeu2LXQI+yUn00oNT8jYGtlik+2/t8269rKvsUmKyn+xp+R34FT736cP+/kCBaEoAxYRCaRcM+CdZ9gFsp3Dbbq329u9DcDpNbbu9jFRq/NtGO2Jk2wp9g53zAUgc4Nlh5XlEz1/vi2GuODCVoXbDrneptj89qJHS3xMh7eHAnDwGPsEz/4qccpokkW0DE2qrujUthM22dS2A+rYdKjbOllBQLVly+Mek16VIiKBlGsGvPg8a8/nH/rybvcZvaEtAA9PtQnUXb6Nze0wyiYIb7/appGs7AXku0492W643e49vFuJ+2Zj/XoJ0GWVdHZMtkEs+V0qxzlU3ZmrALh++SkAPNZ8ashwktJDj/cDYMBIW9Sh6W8WArBuw2G2w6dfxy0WZcAiIoGUawacPcQGR5wz5Ki971tssuTKnvFKGAc8ZJPRnP2QTU7ThpKH7iaLvEVLAFgeGVV7Dnt/r0msA5+bB0D/884B4KV2tphDz98OACDzElvAIH/DxgqPRRmwiEggwSfjERGJp/y1NvnVzr4NAej452sBmNPrcQB6d7jSdoxDX7AyYBGRQJQBi0iVFM2E219u33sTrUJSFYSISKXnvC99dalzbg2wpOLCSQgtvfeNS7tzFTkmUIbjomNSsipyXHRMSlbicSlTAywiIuVHXRAiIoGoARYRCUQNsIhIIGqARUQCUQMsIhKIGmARkUDUAIuIBKIGWEQkEDXAIiKBqAEWEQlEDbCISCBqgEVEAlEDLCISiBpgEZFA1ACLiASiBlhEJBA1wCIigagBFhEJRA2wiEggaoBFRAJRAywiEogaYBGRQNQAi4gEogZYRCQQNcAiIoGoARYRCUQNsIhIIGqARUQCUQMsIhKIGmARkUDUAIuIBKIGWEQkEDXAIiKBqAEWEQlEDbCISCBqgEVEAlEDLCISiBpgEZFA1ACLiASiBlhEJBA1wCIigagBFhEJRA2wiEggaoBFRAJJyAbYOVfdOTfOObfEObfZOTfTOXdW6LhCcs4Nc87NcM7tcM5NCB1PonDOPe+cW+mc2+Scm++cuyp0TKHptbJ7zrn2zrkc59zzoWMBSAsdwG6kAcuAnsBS4GzgH865Q733i0MGFtAKYBRwBlAjcCyJ5I/Ald77Hc65DsCHzrmvvPdfhA4sIL1Wdm808HnoIKISMgP23m/13v/ee7/Ye1/gvX8TWAQcFTq2ULz3E733rwPrQseSSLz3s733O6I/Rr7aBgwpOL1WSuacuxjYALwfOpaohGyAi3POZQHZwOzQsUjicc6Ncc5tA+YCK4G3A4ckCcY5Vxe4E/hl6Fh2lfANsHMuHfgb8Iz3fm7oeCTxeO+HAnWAHsBEYMeeHyFV0F3AOO/98tCB7CqhG2DnXArwHLATGBY4HElg3vt87/1/gIOAIaHjkcThnOsC9AIeCh1LcYl6EQ7nnAPGAVnA2d773MAhSXJIo4r3AcvPnAS0ApZas0JtINU5d4j3/siAcSV0BjwW6Aic673fHjqY0Jxzac65DCAVe/FkOOcS9gM0HpxzTZxzFzvnajvnUp1zZwADSKCLLCHotfIzT2Afyl0iX48Bb2FVIkElZAPsnGsJXIsdrFXOuS2Rr0sDhxbSHcB24FfAwMjtO4JGFJ7HuhuWA+uBB4CbvPeTgkYVnl4ru/Deb/Per4p+AVuAHO/9mtCxOe996BhERKqkhMyARUSqAjXAIiKBqAEWEQlEDbCISCBqgEVEAilTbWA1V91nUKuiYkkIOWxlp9/hSrt/VTgmAJtZv9Z737g0++qYlKwqHBe9f0q2u9dKmRrgDGrR3Z1aflEloOm+bDX8VeGYAEz2rywp7b46JiWrCsdF75+S7e61oi4IEZFA1ACLiASiBlhEJBA1wCIigagBFhEJpCpPUZc05o+3pfAWnTEOgAd/agPA5Iu6ApD/7fwwgYlUUQ0/bgBAirPJzNYct2GfnkcZsIhIIEmTAac2zATA1asLwNK+zQDIaWSfQO3+MAuAgm3bAkRXMVI7HQzAGyePBiDXpwNwXYN5ALxy2OkA1Pk2QHCBuKM6AVBQzV66P5xkRfyzrx8DQK7PL9XznPrffgDU6rOycFtBTk65xRmKq14dgG1nHQ7AYb+298WCblomb3/NH9e18PbnLR4G4NiPrgOgDTP36TmVAYuIBJKwGXBK5w4ALLitBgC/OPQTAEY0fK/E/TtmDQag/RVfxCG6OPlhFQA3zL8YgH93ejVkNEH4Yy2TW3BFNQAeOuUFANJdHgC9amwGINdbLlFAQame99+d/wFAl+d+Ubit9ZAVAOSvXbe/YQeT2rgRAFNGPwbARzn2Fr+/9bkA5C0q0+A9AeaPPRqAz08vWtNzc4GdededWmO/nlsZsIhIIAmTAbtuhwKwcHgqAB+e8FcAGqdan1ZK5LPirW129fH7HU2Aov7Q5058EoC7ul0OgP/8m3iEXaHyN2wEYMny9rahU8BgAvGjfgJgboeJFfL8M497uvD2Gd2HAlD9reTNgIvrkWFnCne3sGsoKcqAy+ykI+YAUCelWuG2oUvOBKDR49P267mVAYuIBKIGWEQkkGBdEKmNbWrM+Q8fCMA/j7Myojbp6ZE9qsfsP35TcwBe73sCAAXVIyVZb1oXRNfqVn60Pcs6xTMqKO54Ss2ybpYeHavuQIsfPrT/Ox1it0/LsdfHL96+2jZEZ6Attsj3MUfasRvf6l8VFGFiS3XKsbb3sYtojUYsAmBHf+vmzFu5ao+P+3HocQDcl2UX357f1LLwvvW3tQAghf3rrtJ/R0QkkGAZ8A8D7cLS7J4PR7akl7jf89HM9zz7NMqfZxmNO6IKXJGqY4MMzs78vMS7fzzK0r76X2cDlXNIcot7ZwBw/j8GxGx3O3MBaL9o+h4fv6FRQwAmf1oHKCpbizrlm/6Ft+tOmQ1QykK25JDv7a/JrWlv9ep72rmSGnjvmwAMqrsMgF5HDQEg4809Z8CXX/c2AF0ig1uuvuv8wvsyP9q/i29RyoBFRAIJlgEf2Htxidtf2XIAAA/Ot2VKsm6xTr38eQti9lt/aN2KCy5B5C+0Pqs7/mlZWt8Bo2Pun33JIwAcsfFGAJpXwgzY5+4EIH/ewn16/OoL7Ozg0GpvRLbE5oArVmQW3q697ft9+h3J4Mej7Ayz+TuBAwlg5c76ABRgJXh5Nfa8ZF1BzyMA6FP7UQByvV1Xysso9VJ3paYMWEQkkHADMa62TOSQ664HoPm/rYqh1mzrl2m0xLK53U2tsi2r/D+NElXbkZ/ajQF73k+KrBlyLAAdBs4FICu15N7PjrcsKrxduml8EpvPtb7x+bk2sVB2utUDbW+9M1hMoSx4pDsArzW0THbsBjsbqv/pDwDkFds/tX49ANaO3ApAszR7zQxfYdefssYVTXNQrNhmnykDFhEJJFgGHO3fbDd8Ucz24p9Ku5PbbfPed6pk0p3VL+aW18dvJfLjMMtSLh9iV64H1n0AiB0+uqu71hwJgN9RuTLD/NU/AnDDd3bd4N0Ob+xp90op9eB2ADx3zlgAtnk7K5j4a5u+tcayz0p83IIxrQH475E2rcHk7VY5U5FTeSoDFhEJJGEm4ylu6W8to8mrGUn3io10uqB9bB3esOUnAVDj3S933a1SiU42XtopFyuD6KT08wfZJEw9T/hvifu92dz6+YqOTWzmuzDXzq36jx0BQIvXVtv+m78r13glHH98FwAuHmd1v9HRsR3etSqh7NdLznwXj7LrBTNOfDCyxZrFW5+yqUoP5JMKiReUAYuIBBM8A06ta/W8OUfbyLj02ywz+brDozH7FfV/xl6rnrK9JgDLr7Gx2T5vTsUFK3ETzWauGP8aAH1qrd3LI/acS9yw0PpED7zPspnKUPFQFrUzK89SXQAuvegMZ+UwWypoxkhrM4raCntNXNDFzoon3WeZbnT5spQDbK6V3mdblVFq5DS7yyeW+ba4t+Iy3yhlwCIigcQ9A44uGrizp03APnzMcwCcXON9AFbn2xXHKdutz++38/sA8EKnCUBRbV5URopd4fz+Ihvt0mae1T1WhgUWBVIjvfkpe8kV9lYh8m5Hy6R7XGqLKNb726flFGFyeDVyZf96jg8cSflYNbhogczPRtp8MtHe/+hr4NlNNtPiPQfYfCH3DLTvt/ey+uDT6tmwwJNrbAFg+g5rO1pcGL/FHJQBi4gEEpcMOCWjaHbedf1tnPVH9zwSs0+nF2xE3EFTrHeu+ls2A1jDpvbp9MJ7RwEwomHsVfDu1S0D/voKe75jl90AQNazswr3qSxL1e8uy6t73I8BoqlY7mNb5nvcebb0y6+usFnNWrxndbup2/dcMb7gSpv7YO6ZYysqxIS27D8lz6Oc7NYMtn7cT279S+G2zQXWBnyba7MH/nrktQBkrLPXyvv3LAaK5oSOZsTRs6po5ty1mu0/fKFdR3q47wV2/6yKu66kDFhEJJAKzYCj/b1zHzyscNvcPrGZb5955wGQfb/NRBUdyZPW/CAADp+0FICbG34LwMYC+5Tq/qrVczbtYPu/f+hLAEz7jT1//wHnFP6OtY9Yf3PGutyY35364Zf7+JeFsbs64KmH21LtvY+50jZ8+nVc46pI0TmO29xStsd1XGArrnBmOQeUJGoviz1NquPs59RDknvu6EMus2x00taswm33PGGTpDT9s1Ut1CR2juh1I6z9Gf5oDwAeavZRic+d6qwK4uZv+gLQbNa35RX2bikDFhEJpEIyYJdmTzvvL4cDMLd30Ty2y/OsyqH345bStHraRiLlRTLf3F7W19v5vq8A+F0Tm4FofGQ9pud+fS4A7SZGavciKx6cdJr1IW/tb0u5v3bEk4W/86BHYisn3txqj3kiu80+/40hdPjgKgC+PeWJEu+ff43VRmZXrQv8JVp9QbvQIQSVUqyLPJrdFdQoeeWZZPHFe4cA8NOLjQq3NZ2353rd7Vl2Der6xh9EttgxOObOYQA0mrU1Zv/mC222tHjUiisDFhEJpEIy4GU32yqkc3tbfd6KvKLZhC6892YAWr1ufb4/nWIzEPmBNvPQK53tMY0j87d2etEy2+wnbCRUzXmx/Tv5a21V0rovRL/b9n5DizoNs/otiQ1wRP3Ijdll/dOCqj7fZubnlLBxlLfotYINFx5RuK3BG5H12TaXbda7lSNsDpE3bvhTZEtVXAUNGkywuVIeu8XOHAfXs/fAguF2ltRuYJi49leLP5R+JGN05fXlfe10oF26vRb+trkpAI0eL3ldt3iOklQGLCISSIVkwGOvHhPz865LKZ07+P8AOPCG9QBcXvefxR4dyXz/bvW87W6zeuD8vNLOFGyajCnqF/Jjit/7Q5meK1E0v8v+phcutRE+l9ZZGXP/ojOfApt+a0EAAAMeSURBVOCsw+2qcEXWL5aHnHPtTKneSKt0mdquaP6P8z+PLP8xb88ZcFpTW0Pwh37Wn//S9TYPcPERk9ERlunbK+M8ebv3wKdnAHDmqVY3m32tVT9Uhfn0Foyw6wBzTrXKqGk7rO/3H717RPYIPxOeMmARkUAqJAP+vy02/KZ7dRtTnbnLely3N5oZs+85c220ydJpVvfb5hWrYmg326offBkz36pgwlLr5xzQ6eWY7cm2UsYZd08Ffj66EWDu7ZFVr7d03+NzXHyc9eO93uQtAAqIvcp/+WLLABeOt3mFG04sud+vssuPzPRVsL3yz5ESrXW+6/wXAcj39sYYNGkwAO3mJ06ZkDJgEZFA1ACLiARSIV0Qn5zcDIDul1q91MbDixY+TFtjp4jZj9mFsLRVNgCjVc4yoGpcHNhfOybYhSfuDxtHRZrT6/EyPsJyiWk51t119fTLAGh39QIAGm6tml0PUW3TrIRx3SC78NlwXOU9HhdN/BCA82tb23Lkp4MAaHdT4nQ9RCkDFhEJpEIy4Px1PwGQ9YiVTWWVsI8ure27BjPt+I5ebxeWrmswL2Q4++yDG2xy8GeHWlY26/inS/3Y5zfZdIsrc21QzdNf2nO1e9LK6NtEprOs6mdU43vaMV1fsB2ARl/b9K5Jdr22TO5+wybTGTDQys9qvF03ZDh7pAxYRCSQ4ItyStlFpxJ8r7N9sr9Ht2J7JPYAjKjodKCtP7OFVY+64cbC+5651gYOdK5m5VOnfGOLam780Pq/W75k1xDyFtkQ2/Z8EYeIk8/Nc/oB0K+lTW6VstUGpFTmRUnb3Gr9271vtfdFQxK3v1sZsIhIIMqAJbjoklEH7rIM+O33Hh2zT22+j/muawilk3mOnS19QK3IluSciL2yUgYsIhKIGmARkUDUAIuIBKIGWEQkEDXAIiKBOO9LPybGObcGWLLXHZNbS+9949LuXEWOCZThuOiYlKyKHBcdk5KVeFzK1ACLiEj5UReEiEggaoBFRAJRAywiEogaYBGRQNQAi4gEogZYRCQQNcAiIoGoARYRCUQNsIhIIP8Psrd+V6ToNdcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "for i in range(10):  \n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.title(y_train[i])\n",
    "    f = plt.imshow(x_train[i])\n",
    "    f.axes.get_xaxis().set_visible(False)\n",
    "    f.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adecuación/preparación de los datos\n",
    "\n",
    "Las imágenes están compuestas por números enteros que representan una escala de grises (`0`: blanco, `255`:negro). El rango real `[0,1]` es mucho más adecuado, por lo que normalizamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255 0 255\n",
      "0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.min(),x_train.max(),x_test.min(),x_test.max())\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "print(x_train.min(),x_train.max(),x_test.min(),x_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reparticionaremos el conjunto de entrenamiento, reservando el 10% de los datos para validación (monitorización del entrenamiento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agruparemos todos los datos en una única variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape = (28, 28)\n",
      "output_categories = 10\n",
      "x_train (54000, 28, 28)\n",
      "y_train (54000,)\n",
      "x_val (6000, 28, 28)\n",
      "y_val (6000,)\n",
      "x_test (10000, 28, 28)\n",
      "y_test (10000,)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Data = namedtuple('Data', 'input_shape output_categories x_train y_train x_val y_val x_test y_test')\n",
    "data = Data(x_train.shape[1:], y_train.max()+1, \n",
    "            x_train, y_train, \n",
    "            x_val, y_val, \n",
    "            x_test, y_test)\n",
    "\n",
    "for name,value in zip(data._fields, data) :\n",
    "    if name == 'input_shape' or name == 'output_categories':\n",
    "        print(name,'=',value)\n",
    "    else :\n",
    "        print(name,value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer modelo: Regresión Logística Multiclase\n",
    "\n",
    "Uno de los modelos más sencillos a implementar es una regresión logística multiclase.\n",
    "\n",
    "<!--\n",
    "![alt text](img/lr.jpg)\n",
    "-->\n",
    "\n",
    "<img src=\"img/lr.jpg\" alt=\"Global Average Pooling\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "El modelo se compone de:\n",
    "\n",
    "   1. `Flatten` : Conversión de las matrices $M$ de entrada de `28x28` en vectores $x$ de `784` componentes.\n",
    "   1. `Dense` :  Transformación afín $y = A \\cdot x + b$ con activación _softmax_ :\n",
    "   \n",
    "       &emsp;&emsp;&emsp;&emsp;$z_i = exp(y_i)/\\sum_{j}^{ }exp(y_j))$\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "def LR(data):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(data.output_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1570      \n",
      "=================================================================\n",
      "Total params: 1,570\n",
      "Trainable params: 1,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LR(data)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de pérdida (`loss`) será la [entropía cruzada](https://es.wikipedia.org/wiki/Entrop%C3%ADa_cruzada), y el optimizados escogido adam ([Adaptive Moment Estimation](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam)). Estamos además interesados en observar el índice de acierto, o _accuracy_ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutaremos 5 iteraciones de entrenamiento, observando la evolución de los conjuntos de entrenamiento y validación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 9 which is outside the valid range of [0, 2).  Label values: 5 4 8 2 1 9 7 6 2 0 0 0 6 8 1 8 8 1 4 7 8 6 6 8 3 3 4 9 0 8 7 0\n\t [[node loss/dense_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_606]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-15880cf87e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 9 which is outside the valid range of [0, 2).  Label values: 5 4 8 2 1 9 7 6 2 0 0 0 6 8 1 8 8 1 4 7 8 6 6 8 3 3 4 9 0 8 7 0\n\t [[node loss/dense_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_606]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(data.x_train, data.y_train, epochs=5, validation_data = (data.x_val, data.y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `train` almacena (entre otras cosas) el historial de la función de coste (`loss`) y la métrica usada (`accuracy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.history['loss'])\n",
    "print(train.history['val_loss'])\n",
    "print(train.history['accuracy'])\n",
    "print(train.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente observamos el resultado frente al conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = model.evaluate(data.x_test, data.y_test, verbose=0)\n",
    "print(f'loss: {test[0]:.4f} acc: {test[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos representar gráficamente además la evolución de la función objetivo de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot(train,test):\n",
    "    n = len(train.history['loss'])\n",
    "    x = list(range(1,n+1))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,train.history['loss'])\n",
    "    plt.plot(x,train.history['val_loss'])\n",
    "    plt.plot(x,[test[0]]*n,linestyle=':', linewidth=4)\n",
    "    plt.title('Training')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "plot(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base al código anterior, creamos una función que permita simplificar la evaluación de distintos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def evaluate(model, data, optimizer='adam', epochs=10):\n",
    "    \n",
    "    model.compile(optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    if len(model.layers) <= 15 :\n",
    "        model.summary()\n",
    "    else :\n",
    "        print(f'Skipping model Summary... it has {len(model.layers)} Layers!')\n",
    "        tr = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "        ntr = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "        print(f'Total params: {tr+ntr}')\n",
    "        print(f'Trainable params: {tr}')\n",
    "        print(f'Non-trainable params: {ntr}')       \n",
    "    \n",
    "    print('\\n----- Train -----')\n",
    "    train = model.fit(data.x_train, data.y_train,\n",
    "                        epochs=epochs, validation_data = (data.x_val, data.y_val),\n",
    "                        verbose = 2)\n",
    "    print('\\n----- Test ------')\n",
    "    test = model.evaluate(data.x_test,  data.y_test, verbose=0)\n",
    "    print(f'loss: {test[0]:.4f} acc: {test[1]:.4f}')\n",
    "    \n",
    "    plot(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La evaluación de un modelo LR será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LR(data)\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con una capa oculta\n",
    "\n",
    "![alt text](img/nn.png)\n",
    "\n",
    "Podemos añadir una capa oculta del tamaño que deseemos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(data, hidden, activation='relu'):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "    \n",
    "    model.add(Dense(hidden, activation=activation))\n",
    "\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate(NN(data, hidden=100), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(NN(data, hidden=200), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(NN(data, hidden=300), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate(NN(data, hidden=1000), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN - Deep Neural Network\n",
    "\n",
    "![alt text](img/dnn.png)\n",
    "\n",
    "Una DNN no es sino una NN conpuesta por múltiples capas ocultas. Podemos añadir tantas capas densas como deseemos...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(data, hidden=(), activation='relu'):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "\n",
    "    for h in hidden :\n",
    "        model.add(Dense(h, activation=activation))\n",
    "        \n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(100,100,100,100,100))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(1024,1024,1024,1024,1024))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout - Evitando el sobreentrenamiento\n",
    "\n",
    "Se trata de una sencilla y (a veces) efectiva regularización que desconecta aleatoriamente las neuronas durante el entrenamiento.\n",
    "\n",
    "\n",
    "<!--\n",
    "![alt text](img/dropout.png)\n",
    "-->\n",
    "\n",
    "<img src=\"img/dropout.png\" alt=\"Global Average Pooling\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "    \n",
    "def DNN(data, hidden=(), activation='relu', dropout=0.2):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "\n",
    "    for h in hidden :\n",
    "        model.add(Dense(h, activation=activation))\n",
    "        if dropout :\n",
    "            model.add(Dropout(dropout))\n",
    "        \n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(1024,1024,1024,1024,1024))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, a menudo un modelo con menor número de parámetros puede tener un comportamiento más que aceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(128,64,32))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(300,))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Convolucionales\n",
    "\n",
    "Una capa convolucional aplica un conjunto de kernels (filtros) que son convolucionados frente a la entrada. El resultado es un `3D-array`. \n",
    "\n",
    "![alt text](img/cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar las capas convolutivas, hay que agregar una dimensión más a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega una dimension de canal\n",
    "data_conv = Data(\n",
    "    data.input_shape+(1,), data.output_categories,\n",
    "    data.x_train[..., tf.newaxis], data.y_train,\n",
    "    data.x_val[..., tf.newaxis], data.y_val,\n",
    "    data.x_test[..., tf.newaxis], data.y_test\n",
    ")\n",
    "for name,value in zip(data_conv._fields, data_conv) :\n",
    "    if name == 'input_shape' or name == 'output_categories':\n",
    "        print(name,'=',value)\n",
    "    else :\n",
    "        print(name,value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "\n",
    "def CNN(data, activation='relu'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation, input_shape=data.input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CNN(data_conv)\n",
    "evaluate(model, data_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pero... y el _dropout_ ?\n",
    "\n",
    "* [Don’t Use Dropout in Convolutional Networks](https://www.kdnuggets.com/2018/09/dropout-convolutional-networks.html), use BatchNormalization instead.\n",
    "   * Parece ser que la regularización mediante _dropout_ no es muy adecuada para las CNN\n",
    "* `BatchNormalization`: Normaliza (**solo** durante el entrenamiento) la media y varianza de los datos de entrada (por batch).\n",
    "\n",
    "La normalización suele ser aplicada antes de la función de activación, por lo que hay que separar a esta última de la capa de convolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "\n",
    "def CNNbnorm(data, activation='relu'):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', input_shape=data.input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CNNbnorm(data_conv)\n",
    "evaluate(model, data_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalmente... sigue pareciéndome más efectivo el dropout..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "def CNNdropout(data, activation='relu', dropout=0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation, input_shape=data.input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CNNdropout(data_conv)\n",
    "evaluate(model, data_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global-average-pooling\n",
    "\n",
    "Las redes convolucioinales deben terminar en una capa densa con activación _softmax_. La última capa densa debe conectarse a otra capa densa, que normalmente será el resultado de aplanar (`Flatten`) la última capa convolucional. La capa `GlobalAveragePooling2D` realiza un promedio de los canales de la capa convolucional anterior, resultando en un vector cuya dimensión es igual al número de canales. El resultado es una reducción sustancial en el número de parámetros del modelo. \n",
    "\n",
    "\n",
    "<!--\n",
    "![alt text](img/gap.png)\n",
    "-->\n",
    "\n",
    "<img src=\"img/gap.png\" alt=\"Global Average Pooling\" style=\"width: 1200px;\"/>\n",
    "\n",
    "* https://adventuresinmachinelearning.com/global-average-pooling-convolutional-neural-networks/\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def CNNgap(data, activation='relu',dropout=0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation, input_shape=data.input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "        \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CNNgap(data_conv)\n",
    "evaluate(model, data_conv, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduciendo resultados ajenos\n",
    "\n",
    "* https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\n",
    "* https://www.kaggle.com/adityaecdrid/mnist-with-keras-for-beginners-99457\n",
    "\n",
    "Primero el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "def XModel(data):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu', input_shape=data.input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo el parámetro _learning-rate_ suele ser modificado _online_ para adaptarse al entrenamiento. Una estrategia sencilla es reducirlo si la función objetivo no decrece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#reduce the LR by half if the training loss is not improved after 1 epochs.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
    "                                            patience=1, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la reducción del learning-rate a los _callbacks_ del entrenamiento: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, optimizer='adam', epochs=10):\n",
    "    \n",
    "    model.compile(optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    if len(model.layers) <= 15 :\n",
    "        model.summary()\n",
    "    else :\n",
    "        print(f'Skipping model Summary... it has {len(model.layers)} Layers!')\n",
    "        tr = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "        ntr = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "        print(f'Total params: {tr+ntr}')\n",
    "        print(f'Trainable params: {tr}')\n",
    "        print(f'Non-trainable params: {ntr}')        \n",
    "    \n",
    "    print('\\n----- Train -----')\n",
    "    train = model.fit(data.x_train, data.y_train,\n",
    "                        epochs=epochs, validation_data = (data.x_val, data.y_val),\n",
    "                        verbose = 2, callbacks=[learning_rate_reduction])\n",
    "    print('\\n----- Test ------')\n",
    "    test = model.evaluate(data.x_test,  data.y_test, verbose=0)\n",
    "    print(f'loss: {test[0]:.4f} acc: {test[1]:.4f}')\n",
    "    \n",
    "    plot(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo, usando un optimizador _RMSprop_ en vez de _Adam_ (por defecto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model = XModel(data_conv)\n",
    "evaluate(model, data_conv, optimizer=optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Red Residual (Residual Network, ResNet)\n",
    "\n",
    " * http://personal.cimat.mx:8181/~mrivera/cursos/aprendizaje_profundo/resnet/resnet.html\n",
    " * https://en.wikipedia.org/wiki/Residual_neural_network\n",
    "\n",
    "Una Red Residual o _ResNet_ contiene conexiones ( _skip connections_ o _shortcuts_ ) que interconectan la salida de una capa con la entrada de una capa no necesariamente contigua, saltando capas intermedias:\n",
    "\n",
    "<img src=\"img/ResNet.png\" alt=\"Residual Network\" style=\"width: 200px;\"/>\n",
    "\n",
    "De una manera conceptual, en la fase inicial del entrenamiento la red es guiada por las conexiones cortocircuito, mientras que según avanza el entrenamiento las capas cortocircuitadas comienzan a aportar, compensando a su vez la aportación del cortocircuito.\n",
    "\n",
    "### Características:\n",
    "\n",
    "   * Mitiga el problema del _desvanecimiento de gradiente_\n",
    "   * Acelera el entrenamiento\n",
    "   * Permite entrenar redes muy profundas (más de 100 capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet identidad\n",
    "\n",
    "Configuración típica:\n",
    "\n",
    "   * Capas convolucionales\n",
    "   * Puente de 2/3 capas\n",
    "   * El cortocircuito se añade antes de la no linealidad\n",
    "\n",
    "<img src=\"img/resnet_identidad.png\" alt=\"resnet identidad\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet convolucional\n",
    "\n",
    "Configuración típica:\n",
    "\n",
    "   * Capas convolucionales\n",
    "   * Puente de 2/3 capas\n",
    "   * El cortocircuito se añade antes de la no linealidad\n",
    "   * Las dimensiones no coinciden.\n",
    "      * Se añade una capa convolucional al cortocircuito\n",
    "      * No se añade no linealidad\n",
    "\n",
    "<img src=\"img/resnet_conv.png\" alt=\"resnet_conv\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RestNet50\n",
    "<img src=\"img/resnet50.png\" alt=\"resnet50\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageNet Challenge\n",
    "\n",
    "* Detección de 1000 categorías de objetos en imágenes\n",
    "\n",
    "|    Red    |  Año | Capas | % Error |\n",
    "|:---------:|:----:|:-----:|:-------:|\n",
    "|  AlexNet  | 2013 |   8   |   11.7  |\n",
    "|    VGG    | 2014 |   19  |   7.3   |\n",
    "| Inception | 2014 |   22  |   6.7   |\n",
    "|   ResNet  | 2015 |  152  |   3.6   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de una RestNet\n",
    "* No es una red secuencial\n",
    "* No podemos implementarla mediante `tensorflow.keras.models.Sequential`\n",
    "* TensorFlow permite una descripción *funcional* del modelo\n",
    "    * Muy similar a lo visto previamente\n",
    "    * Mayor livertad de diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Functional API\n",
    "\n",
    "Implementación previa (`Sequential`):\n",
    "\n",
    "```python\n",
    "def LR(data):    \n",
    "    model = Sequential()  \n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    return model\n",
    "```\n",
    "\n",
    "Implementación funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "def LR(data):\n",
    "\n",
    "    x_input = Input(shape=data.input_shape)\n",
    "\n",
    "    x = Flatten()(x_input)\n",
    "    x = Dense(data.output_categories, activation='softmax')(x)\n",
    "    \n",
    "    return Model(x_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LR(data)\n",
    "evaluate(model, data, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN - Functional API\n",
    "\n",
    "Implementación previa (`Sequential`):\n",
    "\n",
    "```python\n",
    "def DNN(data, hidden=(), activation='relu', dropout=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=data.input_shape))\n",
    "    for h in hidden :\n",
    "        model.add(Dense(h, activation=activation))\n",
    "        if dropout :\n",
    "            model.add(Dropout(dropout))\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    return model\n",
    "```\n",
    "\n",
    "Implementación funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "    \n",
    "def DNN(data, hidden=(), activation='relu', dropout=0.2):\n",
    "\n",
    "    x_input = Input(shape=data.input_shape)\n",
    "\n",
    "    x = Flatten()(x_input)\n",
    "    for h in hidden :\n",
    "        x = Dense(h, activation=activation)(x)\n",
    "        if dropout :\n",
    "            x = Dropout(dropout)(x)\n",
    "    x = Dense(data.output_categories, activation='softmax')(x)\n",
    "    \n",
    "    return Model(x_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(data, hidden=(128,64,32))\n",
    "evaluate(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Functional API\n",
    "\n",
    "Implementación previa (`Sequential`):\n",
    "\n",
    "```python\n",
    "def CNN(data, activation='relu',dropout=0.2):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation, input_shape=data.input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation=activation))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout))\n",
    "        \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(data.output_categories, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "```\n",
    "\n",
    "Implementación funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(data, activation='relu',dropout=0.2):\n",
    "    \n",
    "    x_input = Input(shape=data.input_shape)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=3, padding='same', activation=activation)(x_input)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters=32, kernel_size=3, padding='same', activation=activation)(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='same', activation=activation)(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "        \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(data.output_categories, activation='softmax')(x)\n",
    "    \n",
    "    return Model(x_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNgap(data_conv)\n",
    "evaluate(model, data_conv, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RestNet - Functional API (no hay otra...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add\n",
    "\n",
    "def ResNet(data,n=1):\n",
    "\n",
    "    x_input = Input(shape=data.input_shape)\n",
    "    \n",
    "    x = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same')(x_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    for i in range(n):\n",
    "        x_id = x\n",
    "        x = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same')(x_input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation='relu')(x)\n",
    "        x = Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([x, x_id])\n",
    "        x = Activation(activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "\n",
    "    for i in range(n):\n",
    "        x_id = x\n",
    "        x = Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation='relu')(x)\n",
    "        x = Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([x, x_id])\n",
    "        x = Activation(activation='relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(data.output_categories, activation = \"softmax\")(x)    \n",
    "\n",
    "    return Model(x_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(data_conv)\n",
    "#model.summary()\n",
    "evaluate(model, data_conv, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(data_conv,n=10)\n",
    "evaluate(model, data_conv, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet2(data):\n",
    "    \n",
    "    x_input = Input(shape=data.input_shape)\n",
    "    \n",
    "    x = Conv2D(32, 3, activation='relu')(x_input)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    block_1_output = MaxPool2D(3)(x)\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_2_output = Add()([x, block_1_output])\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_3_output = Add()([x, block_2_output])\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)    \n",
    "    x = Dense(data.output_categories, activation = \"softmax\")(x)    \n",
    "\n",
    "    return Model(x_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ResNet2(data_conv)\n",
    "evaluate(model, data_conv, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1068px",
    "left": "2048px",
    "top": "110px",
    "width": "238px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
